# =============================================================================
# RLLM Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your API keys.
# The --model flag auto-detects the provider, so you only need to set
# the API key for the provider you're using.

# -----------------------------------------------------------------------------
# API Keys (set at least one)
# -----------------------------------------------------------------------------

# OpenAI API Key (for gpt-5-mini, gpt-5-nano, gpt-4o, gpt-4o-mini, etc.)
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# xAI Grok API Key (for grok-4, grok-4-1-fast-reasoning, etc.)
# Get your key at: https://console.x.ai/
XAI_API_KEY=your-xai-api-key-here

# Anthropic API Key (for claude-opus-4-6, claude-sonnet-4-5, claude-haiku-4-5)
# Get your key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# -----------------------------------------------------------------------------
# Available Models
# -----------------------------------------------------------------------------
# OpenAI models (auto-detected by 'gpt-' or 'o1/o3/o4' prefix):
#   - gpt-5-mini          (128k context, recommended for most tasks)
#   - gpt-5-nano          (128k context, faster/cheaper)
#   - gpt-4.1             (128k context)
#   - gpt-4.1-mini        (128k context)
#   - gpt-4.1-nano        (128k context)
#   - gpt-4o              (128k context)
#   - gpt-4o-mini         (128k context)
#
# xAI Grok models (auto-detected by 'grok' prefix):
#   - grok-4-1-fast-reasoning       (128k context)
#   - grok-4-1-fast-non-reasoning   (128k context)
#   - grok-4-fast-reasoning         (128k context)
#   - grok-4-fast-non-reasoning     (128k context)
#   - grok-4                        (128k context)
#
# Anthropic Claude models (auto-detected by 'claude' prefix):
#   - claude-opus-4-6               (200k context, best as orchestrator)
#   - claude-sonnet-4-5-20250514    (200k context, smart sub-tasks)
#   - claude-haiku-4-5-20250514     (200k context, fast/simple sub-tasks)

# -----------------------------------------------------------------------------
# Optional: Default Model Configuration
# -----------------------------------------------------------------------------
# DEFAULT_MODEL=gpt-5-mini
# DEFAULT_SUB_MODEL=gpt-5-nano
# DEFAULT_SIMPLE_MODEL=
#
# Multi-model Anthropic setup (recommended):
# DEFAULT_MODEL=claude-opus-4-6
# DEFAULT_SUB_MODEL=claude-sonnet-4-5-20250514
# DEFAULT_SIMPLE_MODEL=claude-haiku-4-5-20250514

# -----------------------------------------------------------------------------
# Optional: Budget Limits
# -----------------------------------------------------------------------------
# MAX_COST_USD=10.0
# MAX_TOKENS=1000000

# -----------------------------------------------------------------------------
# Optional: Cache Configuration
# -----------------------------------------------------------------------------
# ENABLE_CACHE=true
# CACHE_SIZE=1000
# CACHE_TTL=3600

# -----------------------------------------------------------------------------
# Optional: Logging
# -----------------------------------------------------------------------------
# LOG_LEVEL=INFO
